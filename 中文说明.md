# NPU微架构 - 中文说明

## 项目简介

这是一个完整的NPU（神经网络处理单元）微架构实现，使用Verilog HDL编写，专门用于学习和理解硬件加速器的设计原理。

## 核心特性

### 1. 脉动阵列架构
- **8×8 PE阵列**：64个处理单元并行工作
- **高效数据流**：数据从左向右流动，减少通信开销
- **灵感来源**：Google TPU的脉动阵列设计

### 2. 完整的计算流程
```
输入数据 → 矩阵乘法 → 激活函数 → 输出结果
```

### 3. 多种激活函数
- **ReLU**：最常用，速度最快
- **Sigmoid**：用于二分类，使用查找表优化
- **Tanh**：输出范围[-1,1]，适合归一化

### 4. 标准系统接口
- **AXI4-Lite协议**：业界标准总线接口
- **寄存器映射**：清晰的控制和状态寄存器
- **中断支持**：计算完成自动通知

## 模块说明

### 核心计算模块

#### 1. 处理单元（processing_element.v）
**功能**：执行乘累加（MAC）运算
```
输出 = 累加器 + (输入数据 × 权重)
```

**关键特性**：
- 16位定点数运算（Q8.8格式）
- 32位累加器防止溢出
- 支持清零和使能控制

#### 2. 矩阵乘法单元（matrix_multiply_unit.v）
**功能**：使用64个PE组成8×8阵列，执行矩阵乘法

**工作原理**：
1. 输入数据从左侧进入
2. 在PE阵列中向右流动
3. 每个PE执行一次MAC运算
4. 结果在右侧输出

**性能**：
- 每周期64次MAC运算
- 延迟约8个周期（矩阵维度）

#### 3. 激活函数单元（activation_unit.v）
**功能**：对矩阵乘法结果应用非线性激活函数

**实现方法**：
- ReLU：简单比较逻辑
- Sigmoid：查找表（LUT）+ 线性插值
- Tanh：基于Sigmoid的近似计算

### 存储模块

#### 4. 输入缓存（input_buffer.v）
- **容量**：256×16bit = 512字节
- **类型**：双端口RAM
- **用途**：存储输入特征数据

#### 5. 权重缓存（weight_buffer.v）
- **容量**：1024×16bit = 2KB
- **类型**：双端口RAM
- **用途**：存储神经网络权重

#### 6. 输出缓存（output_buffer.v）
- **容量**：256×16bit = 512字节
- **类型**：双端口RAM
- **用途**：存储计算结果

### 控制和接口模块

#### 7. 控制单元（control_unit.v）
**功能**：NPU的"大脑"，协调各模块工作

**状态机流程**：
```
空闲 → 加载配置 → 加载数据 → 计算 → 激活 → 写回 → 完成
```

**保护机制**：
- 超时检测
- 错误处理
- 配置检查

#### 8. AXI接口（axi_interface.v）
**功能**：连接NPU与系统总线

**支持的操作**：
- 寄存器读写
- 数据传输
- 中断管理

**寄存器映射**：
| 地址 | 名称 | 功能 |
|------|------|------|
| 0x000 | CTRL_REG | 控制寄存器 |
| 0x004 | STATUS_REG | 状态寄存器 |
| 0x008 | CONFIG_REG | 配置寄存器 |
| 0x00C | INT_STATUS | 中断状态 |

#### 9. 顶层模块（npu_top.v）
**功能**：集成所有子模块，提供完整的NPU功能

## 数据格式：Q8.8定点数

### 什么是Q8.8？
- **8位整数部分**：表示-128到127
- **8位小数部分**：表示0到0.996（精度1/256）
- **总共16位**：符号位 + 整数 + 小数

### 为什么使用定点数？
1. **硬件简单**：不需要复杂的浮点运算单元
2. **功耗低**：计算效率高
3. **面积小**：占用更少的芯片资源
4. **精度足够**：对于推理任务，Q8.8精度已足够

### 转换示例
```
十进制    →  Q8.8     →  二进制
1.0       →  0x0100   →  0000_0001.0000_0000
0.5       →  0x0080   →  0000_0000.1000_0000
2.5       →  0x0280   →  0000_0010.1000_0000
-1.0      →  0xFF00   →  1111_1111.0000_0000
```

## 使用示例

### 完整的计算流程

```c
// 1. 初始化NPU
void npu_init() {
    // 软复位
    write_reg(CTRL_REG, 0x01);
    write_reg(CTRL_REG, 0x00);
    
    // 配置：8×8矩阵，ReLU激活
    write_reg(CONFIG_REG, 0x0108);
}

// 2. 加载数据
void npu_load_data(float* input, float* weight) {
    // 转换为Q8.8格式并加载
    for (int i = 0; i < 8; i++) {
        uint16_t q88_input = float_to_q88(input[i]);
        write_reg(INPUT_MEM + i*4, q88_input);
    }
    
    for (int i = 0; i < 64; i++) {
        uint16_t q88_weight = float_to_q88(weight[i]);
        write_reg(WEIGHT_MEM + i*4, q88_weight);
    }
}

// 3. 执行计算
void npu_compute() {
    // 启动计算
    write_reg(CTRL_REG, 0x02);
    
    // 等待完成
    while (read_reg(STATUS_REG) & 0x01) {
        // 忙等待
    }
}

// 4. 读取结果
void npu_read_result(float* output) {
    for (int i = 0; i < 8; i++) {
        uint16_t q88_output = read_reg(OUTPUT_MEM + i*4);
        output[i] = q88_to_float(q88_output);
    }
}

// 辅助函数：浮点数转Q8.8
uint16_t float_to_q88(float f) {
    return (uint16_t)(f * 256.0);
}

// 辅助函数：Q8.8转浮点数
float q88_to_float(uint16_t q88) {
    return (float)q88 / 256.0;
}
```

## 仿真和测试

### 运行仿真

#### 方法1：使用提供的脚本（推荐）
```bash
# Linux/Mac
bash run_sim.sh

# Windows (Git Bash)
bash run_sim.sh
```

#### 方法2：使用ModelSim
```bash
vsim -do run_modelsim.do
```

#### 方法3：手动编译
```bash
# 编译
iverilog -o npu_sim \
    rtl/processing_element.v \
    rtl/matrix_multiply_unit.v \
    rtl/activation_unit.v \
    rtl/input_buffer.v \
    rtl/weight_buffer.v \
    rtl/output_buffer.v \
    rtl/control_unit.v \
    rtl/axi_interface.v \
    rtl/npu_top.v \
    testbench/npu_tb.v

# 运行
vvp npu_sim

# 查看波形
gtkwave npu_tb.vcd
```

### 测试用例说明

测试平台（npu_tb.v）包含一个完整的测试：
- **测试类型**：单位矩阵乘法
- **输入向量**：[1, 1, 1, 1, 1, 1, 1, 1]
- **权重矩阵**：8×8单位矩阵
- **期望输出**：[1, 1, 1, 1, 1, 1, 1, 1]

这个测试验证了：
1. AXI接口的读写功能
2. 数据加载和存储
3. 矩阵乘法计算
4. 激活函数应用
5. 中断机制

## 性能分析

### 计算性能
```
PE数量：64个
时钟频率：100MHz
理论峰值：6.4 GMAC/s（64 × 100M）
实际性能：约5-6 GMAC/s（考虑控制开销）
```

### 延迟分析
```
8×8矩阵乘法总延迟：约13周期
- 数据加载：2周期
- 矩阵计算：8周期
- 激活函数：1周期
- 数据写回：2周期

在100MHz下：130纳秒
```

### 资源占用（FPGA）
```
LUT（查找表）：约5000个
FF（触发器）：约3000个
DSP48（乘法器）：64个
BRAM（块RAM）：4-6块
估计功耗：1-2瓦
```

## 学习路线建议

### 第一周：基础理解
1. 阅读README.md了解项目
2. 学习Q8.8定点数格式
3. 理解processing_element.v（PE模块）
4. 手动计算几个MAC运算

### 第二周：核心模块
1. 学习脉动阵列原理
2. 理解matrix_multiply_unit.v
3. 画出数据流图
4. 模拟一次矩阵乘法过程

### 第三周：系统集成
1. 学习AXI4-Lite协议
2. 理解control_unit.v状态机
3. 画出状态转换图
4. 理解完整的计算流程

### 第四周：实践验证
1. 运行仿真，观察波形
2. 修改测试用例
3. 尝试不同的激活函数
4. 添加新功能

## 扩展项目建议

### 初级项目
1. **修改矩阵大小**：改为4×4或16×16
2. **添加新激活函数**：Leaky ReLU, PReLU
3. **性能计数器**：统计MAC操作次数和周期数
4. **更多测试用例**：测试边界条件

### 中级项目
1. **卷积加速**：添加卷积专用硬件
2. **池化单元**：实现Max Pooling和Average Pooling
3. **批处理**：一次处理多个输入向量
4. **流水线优化**：提高吞吐量

### 高级项目
1. **DMA控制器**：自动数据传输，减少CPU干预
2. **INT8量化**：支持8位整数量化推理
3. **稀疏矩阵**：跳过零值计算，提高效率
4. **FPGA实现**：在真实硬件上运行和验证
5. **完整神经网络**：支持多层网络自动执行

## 常见问题解答

### Q1：为什么选择8×8的PE阵列？
**A**：这是教学和资源的平衡：
- 足够展示脉动阵列原理
- FPGA资源占用适中
- 仿真时间合理
- 易于理解和调试

实际商用NPU通常使用更大的阵列（如Google TPU的256×256）。

### Q2：这个NPU能用于实际应用吗？
**A**：这是一个教学项目，主要用于学习。实际应用需要：
- 更大的PE阵列
- 更多的缓存
- DMA支持
- 更完善的错误处理
- 软件驱动和工具链

### Q3：如何在FPGA上实现？
**A**：步骤如下：
1. 使用Vivado或Quartus打开项目
2. 添加约束文件（时钟、引脚等）
3. 综合和实现
4. 生成比特流
5. 下载到FPGA
6. 编写软件驱动测试

推荐使用Xilinx 7系列或更高版本FPGA。

### Q4：如何提高性能？
**A**：优化方向：
1. **增大PE阵列**：16×16或更大
2. **提高时钟频率**：优化关键路径
3. **添加流水线**：减少组合逻辑延迟
4. **数据重用**：减少内存访问
5. **并行处理**：同时处理多个层

### Q5：支持训练吗？
**A**：当前设计仅支持推理（前向传播）。训练需要：
- 反向传播支持
- 梯度计算和更新
- 更高的数值精度
- 更大的存储空间

这需要大幅扩展设计。

## 参考资料

### 推荐阅读
1. **《数字集成电路设计》** - Rabaey
   - 数字电路基础
   
2. **《计算机体系结构：量化研究方法》** - Hennessy & Patterson
   - 计算机架构原理
   
3. **《深度学习》** - Goodfellow et al.
   - 神经网络基础

### 在线资源
1. **HDLBits** - Verilog练习
2. **CS231n** - Stanford深度学习课程
3. **ARM AMBA规范** - AXI协议文档

### 相关论文
1. "Systolic Arrays" - H.T. Kung (1982)
2. "In-Datacenter Performance Analysis of a TPU" - Google (2017)
3. "Eyeriss: An Energy-Efficient Reconfigurable Accelerator" - MIT (2016)

## 文档导航

- **README.md** - 项目概述和快速开始
- **ARCHITECTURE.md** - 详细架构设计（英文）
- **LEARNING_GUIDE.md** - 学习指南（英文）
- **QUICK_REFERENCE.md** - 快速参考卡片
- **PROJECT_SUMMARY.md** - 项目总结
- **本文档** - 中文详细说明

## 致谢

本项目受以下工作启发：
- Google TPU架构
- MIT Eyeriss项目
- Xilinx DPU设计
- 各种开源NPU项目

感谢所有为硬件加速器研究做出贡献的研究者和工程师！

## 联系和反馈

如有问题或建议，欢迎交流讨论。

---

**祝你学习愉快！希望这个项目能帮助你理解NPU的设计原理。** 🚀

**记住**：理解原理比记住代码更重要。多思考"为什么"，而不仅仅是"怎么做"。
